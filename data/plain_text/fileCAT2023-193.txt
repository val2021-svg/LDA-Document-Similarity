   2SC8010 - Sparse representations of signals       Instructors: Stephane Rossignol  Department: CAMPUS DE METZ  Language of instruction: FRANCAIS  Campus: CAMPUS DE METZ  Workload (HEE): 60  On-site hours (HPE): 34,50          Description  The parsimonious representation of signals is one of the fundamental  concepts in data science. Parsimonious representations make it possible to  represent complex signals (such as sounds) by a small number of non-zero  coefficients, this in very large spaces. They thus make it possible to find  structures or regularities in very large spaces. These representations are at  the heart of the mathematical understanding of the effectiveness of recent  algorithms and techniques of supervised or unsupervised learning and  scattering transformations.    The lecture introduces some mathematical tools used in signal analysis and  their properties (complements about the Fourier transform, subsampling,  oversampling, harmonic signal, STFT, multi-resolution analysis, PaleyLittlewood wavelet decompositions, and bi-orthogonal analysis, perfect  reconstruction filter banks) as well as signal decomposition methods  (Matching Pursuit, Basis Pursuit, Independent Component Analysis).       Quarter number  ST7    Prerequisites (in terms of CS courses)  Probability, statistics, signal processing (1CC4000 and 1CC5000) and first  year algorithmic lectures (1CC1000); a good knowledge of a programming  environment (Matlab/Octave, Python).     Syllabus   Harmonic analysis: reminders and complements on the Fourier  transform (under/over-sampling, DFT, filter banks, harmonic signal,  Hilbert transform, short term Fourier transform (STFT)).    Multi-resolution analysis: Paley-Littlewood wavelet decomposition, biorthogonal, perfect reconstruction filter banks.   597        Decomposition of a signal: dictionary, parsimonious representation,  matching pursuit, orthogonal matching pursuit, basis pursuit.    Independent component analysis: notions of entropy, entropy rate of  a random signal, mutual information, independent component analysis  (ACI), ACI in an orthonormal basis, blind deconvolution.    Concepts of supervised learning: introduction to basic notions of  learning, test basis, over-learning, empirical risk, real risk (or  generalization)     Class components (lecture, labs, etc.)  17.5h Lecture  9h Tutorials  8h Labs. A single topic.     Grading  Continuous monitoring (50%, 2/3 MCT at the beginning of the tutorials;  individual score) and oral presentation at the very end of the labs  (50%).  Labs : grading by pair; differentiated in the event of an anomaly in a  pair.     Course support, bibliography  A wavelet tour of signal processign, Stéphane Mallat    https://www.di.ens.fr/~mallat/papiers/WaveletTourChap1-2-3.pdf       Resources  Teacher : Stéphane Rossignol    Room size for tutorials : 34  Max room size for labs : 34    Software : Matlab (34 licences)/Octave (Python)    Rooms for labs : rooms on Metz campus     Learning outcomes covered on the course    •  Being able to design a complete signal processing chain.  •  Being able to compare the performances of the various tools at our   disposal for the analysis of complicated time series, in order to   598      choose the one which will be best suited for this or that signal to be  analyzed.   •  Being able use correctly the basic and advanced principles of analog   signal processing and digital signal processing.        Description of the skills acquired at the end of the course    C2. Develops in-depth skills in an engineering field and a family of  professions.  C6. Be operational, responsible, and innovative in the digital world.   599   